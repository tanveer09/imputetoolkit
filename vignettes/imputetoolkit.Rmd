---
title: "imputetoolkit"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{imputetoolkit}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, include = FALSE}
# Disable vignette examples if the sample dataset is not found
file_path <- system.file("extdata", "sample_dataset.csv", package = "imputetoolkit")
if (!nzchar(file_path) || !file.exists(file_path)) {
  warning("Sample dataset not found. Code chunks will not be evaluated.")
  knitr::opts_chunk$set(eval = FALSE)
}
```

```{r load}
library(imputetoolkit)
```

---

# Introduction

Handling **missing data** is one of the most common and crucial challenges in data science.
Whether caused by *sensor errors*, *survey non-responses*, or *data-entry mistakes*, missingness can bias results and reduce model accuracy.

Simple strategies like **listwise deletion** often waste valuable data.
More robust approaches involve **imputation** — replacing missing values with reasonable estimates.

However, no single imputation method is universally best.
The **`imputetoolkit`** package helps you **compare, evaluate, and visualize** different methods consistently.

---

# What the Package Does

`imputetoolkit` provides a full benchmarking pipeline for missing-data methods:

- Injects controlled missingness into data
- Applies multiple imputation methods:

* Mean/Mode (with skewness-aware log transform)
* Median/Mode
* MICE (Predictive Mean Matching)
* KNN (parallel mixed-type imputation)

- Evaluates each method using Rcpp-optimized metrics:

* RMSE, MAE, R², Correlation, KS statistic, and Accuracy

- Scales numeric data per-column using **min–max scaling**
- Provides plots and summary tables for easy comparison

---

# Typical Workflow

The **main entry point** is the `evaluator()` function:

```r
res <- evaluator(filename = "path/to/data.csv")
```

Internally, it performs:

1. Load or receive the data frame.
2. Identify and inject additional missingness.
3. Compute min–max values for scaling numeric columns.
4. Impute using Mean/Mode, Median/Mode, MICE, and KNN.
5. Evaluate each method with global and per-column metrics.
6. Return a structured list of `evaluator` objects.

---

# Example 1 – Quick Start

```{r, eval=FALSE}
# Load the built-in dataset
file <- system.file("extdata", "sample_dataset.csv", package = "imputetoolkit")
raw_data <- read.csv(file, stringsAsFactors = TRUE)

# Run the evaluator
res <- evaluator(data = raw_data)
```

### View Metrics for One Method

```{r, eval=FALSE}
print(res$mean_mode)
```

### Detailed Per-Column Summary

```{r, eval=FALSE}
summary(res$mean_mode)
```

### Compare All Methods (Table)

```{r, eval=FALSE}
print_metrics(res)
```

### Compare All Methods (Plot)

```{r, eval=FALSE, fig.width=7, fig.height=5}
plot_metrics(res, "ALL")
```

---

# Example 2 – KNN and Log-Transform Aware Mean Imputation

The new version introduces:

* **KNN imputation** using `FNN` + parallelism via `foreach` and `doParallel`.
* **Log-based mean imputation** for highly skewed numeric features.

You can monitor KNN progress in the console:

```
Running mixed-type parallel KNN imputation using FNN...
Using 8 cores for KNN imputation...
Parallel mixed-type KNN imputation complete (parallel).
```

Each method’s results are stored as:

* `res$mean_mode`
* `res$median_mode`
* `res$mice`
* `res$knn`

All share the same structure and S3 class `"evaluator"`.

---

# Example 3 – Suggesting the Best Method

```{r, eval=FALSE}
# Suggest best based on one metric
suggest_best_method(res, "RMSE")

# Suggest across all metrics
suggest_best_method(res, "ALL")
```

Example output:

```
Suggested best imputation methods across metrics:
    As per RMSE, MAE: KNN
    As per R2, KS, Accuracy: MICE
```

---

# Example 4 – Visualizing Density Comparisons

After imputation, you can visualize the distributional agreement between **true** and **imputed** values.

```{r, eval=FALSE}
# Extract evaluation lists
eval_list <- get_eval_list(res)

# Plot for a specific numeric column
plot_density_per_column(eval_list, "age")

# Combined density plots for all columns × methods
plot_density_all(eval_list)
```

These plots make it easy to see whether imputed values preserve each variable’s shape and spread.

---

# Example 5 – Full Automated Report

The helper `evaluate_results()` runs the whole analysis:

```{r, eval=FALSE}
evaluate_results(res, metric = "RMSE")
```

This function:

1. Prints a metrics table (`print_metrics()`)
2. Displays bar plots of results (`plot_metrics()`)
3. Recommends the best method (`suggest_best_method()`)

---

# Evaluation Metrics

| Metric          | Meaning                                                | Higher/Lower Better |
| :-------------- | :----------------------------------------------------- | :-----------------: |
| **RMSE**        | Root Mean Squared Error between true & imputed values  |          ↓          |
| **MAE**         | Mean Absolute Error                                    |          ↓          |
| **R²**          | Proportion of variance explained                       |          ↑          |
| **Correlation** | Pearson correlation between true & imputed             |          ↑          |
| **KS**          | Kolmogorov–Smirnov statistic (distribution similarity) |          ↑          |
| **Accuracy**    | % of exact matches (categorical)                       |          ↑          |

---

# Example 6 – Custom Datasets

You can pass any data frame directly:

```{r, eval=FALSE}
df <- read.csv("custom_data.csv")
res <- evaluator(data = df)
```

Or use any file type supported by the package (`.csv`, `.tsv`, `.xlsx`, `.rds`).

---

# Behind the Scenes

### Parallelized KNN

* Uses `FNN::get.knnx()` for nearest-neighbor search.
* Runs in parallel (`doParallel`) for speed.
* Handles both numeric and categorical variables separately.

### Skewness-Aware Mean

* Uses `e1071::skewness()` to detect skewness.
* If |skewness| > 1, applies **log-transform + geometric mean**.
* Back-transforms to preserve scale.

### Scaled Evaluation

* Numeric columns are scaled to [0, 1] using stored min–max values.
* Ensures fair metric comparison across features.

---

# Summary

The `imputetoolkit` package automates **end-to-end benchmarking** of imputation strategies.
It’s ideal for teaching, exploratory data analysis, and reproducible research.

✔ Unified API for multiple imputation methods
✔ Rcpp-accelerated evaluation metrics
✔ Parallel KNN support
✔ Density visualization for true vs imputed
✔ Automatic method suggestion

---

# Further Reading

For detailed examples:

```r
vignette("imputetoolkit")
```

or explore the GitHub repository for:

* Additional sample datasets
* Unit tests (`testthat/`)
* The tester project demonstrating complete end-to-end runs

---

# Citation

If you use this package, please cite:

> Singh, Tanveer. (2025). *imputetoolkit: An R Package for Evaluating Missing Data Imputation Methods*.
> Victoria University of Wellington.

---
